<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Theory and Methods • sjosmooth</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/yeti/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Theory and Methods">
<meta property="og:description" content="">
<meta property="og:image" content="http://www.danieldsjoberg.com/sjosmooth/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">sjosmooth</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/TheoryMethods.html">Methods</a>
    </li>
    <li>
      <a href="../articles/sm_predict.html">sm_predict()</a>
    </li>
    <li>
      <a href="../articles/sm_regression.html">sm_regression()</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/ddsjoberg/sjosmooth">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Theory and Methods</h1>
                        <h4 class="author">Daniel D. Sjoberg</h4>
            
            <h4 class="date">2018-12-26</h4>
      
      
      <div class="hidden name"><code>TheoryMethods.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>The <strong>sjosmooth</strong> package (pronounced sō smüt͟h) was built to perform kernel smoothing on any type of regression model, but the focus is on censored time-to-event or survival data. The package provides kernel smoothed estimates of survival probabilities at specified times, as well as other outcomes from survival regression models. The <strong>sm</strong> package is closely related to the <strong>sjosmooth</strong> package in that it also performs kernel smoothing with censored time-to-event data; however, the <strong>sm</strong> package only allows for univariate estimation of a survival quantile (i.e. median survival time) using the Gaussian kernel (<code>sm::sm.survival()</code>). <strong>sjosmooth</strong> allows for the use of other kernels and for an n-dimensional covariate smoothing matrix.</p>
<p>I’ll do a brief review of the theory underlying kernel smoothing, and a brief review on simulating time-to-event data. Other vignettes focus on the usage of the <strong>sjosmooth</strong> package in the univariate setting, and for obtaining kernel-smoothed survival estimates for 2 or more covariates.</p>
<p><left><img src="https://raw.githubusercontent.com/simplystats/simplystats.github.io/master/_images/loess.gif" style="width:40.0%"></left></p>
<p>simplystatistics.org. loess explained in a GIF </p>
</div>
<div id="kernel-smoothing-theory" class="section level2">
<h2 class="hasAnchor">
<a href="#kernel-smoothing-theory" class="anchor"></a>Kernel Smoothing Theory</h2>
<p>Kernel smoothing is a technique for estimating a function when a parametric model for the function is unknown. The kernel smoothing methods utilized in the <strong>sjosmooth</strong> package are described in detail in the sixth chapter of the second edition of Hastie, Tibshirani, and Friedman’s book entitled <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>.</p>
<p>The <strong>sjosmooth</strong> package currently supports four kernels: Epanechnikov, Tri-cube, Gaussian, and flat. The kernel specifies how much weight is given to each observation in your dataset when performing weighted regression. The figure below illustrates three kernels.</p>
<p><img src="TheoryMethods_files/figure-html/kernels-1.png" width="700"></p>
<p>For the Epanechnikov, Tri-cube, and flat kernels, the <span class="math inline">\(\lambda\)</span> parameter is on the standardized scale. For example, if <span class="math inline">\(\lambda = 1\)</span> then observations within 1 standard deviation would be included in the kernel-weighted estimate. If <span class="math inline">\(\lambda = 0.5\)</span> then only observations within half a standard deviation would be included.</p>
<div id="epanechnikov-kernel" class="section level4">
<h4 class="hasAnchor">
<a href="#epanechnikov-kernel" class="anchor"></a>Epanechnikov kernel</h4>
<p>The Epanechnikov quadratic kernel is<br><span class="math display">\[
K_\lambda(x_0, x) = D\Big( \frac{||x - x_0||}{\lambda} \Big)
\]</span> with <span class="math display">\[
D(t) = 
\begin{cases} 
      \frac{3}{4}(1-t^2) &amp; |t| \le 1 \\
      0 &amp; |t| &gt; 1 \\
\end{cases}
\]</span> The <span class="math inline">\(\lambda\)</span> parameter is the radius of the circle (or hypersphere for higher dimensions). Any observation that is further than <span class="math inline">\(\lambda\)</span> units from <span class="math inline">\(x_0\)</span> is not included in the weighted estimate. Observations closer to <span class="math inline">\(x_0\)</span> receive higher weight.</p>
</div>
<div id="tri-cube-kernel" class="section level4">
<h4 class="hasAnchor">
<a href="#tri-cube-kernel" class="anchor"></a>Tri-cube kernel</h4>
<p>The tri-cube kernel is similarly defined similarly to the Epanechnikov kernel, except <span class="math display">\[
D(t) = 
\begin{cases} 
      (1-|t|^3)^3 &amp; |t| \le 1 \\
      0 &amp; |t| &gt; 1 \\
\end{cases}
\]</span> The parameter has a similar interpretation here as it does with the Epanechnikov kernel.</p>
</div>
<div id="gaussian-kernel" class="section level4">
<h4 class="hasAnchor">
<a href="#gaussian-kernel" class="anchor"></a>Gaussian kernel</h4>
<p>The Gaussian kernel is given by <span class="math display">\[
K_\lambda(x_0, x) = \frac{1}{\sqrt{2\pi\lambda^2}^N} exp\Bigg(-\frac{||x - x_0||^2}{2\lambda^2}\Bigg)
\]</span> where <span class="math inline">\(N\)</span> is the dimension of the covariate, or predictor, vector. Here, the weights are defined by the Gaussian distribution and is the standard deviation. The primary difference here is that all observations are included in the estimation at every point; although, observations further from our point estimate, <span class="math inline">\(x_0\)</span>, will be included with much less weight.</p>
</div>
<div id="flat-kernel" class="section level4">
<h4 class="hasAnchor">
<a href="#flat-kernel" class="anchor"></a>Flat kernel</h4>
<p>The flat kernel gives all observations within a certain distance equal weight. The kernel is given by <span class="math display">\[
K_\lambda(x_0, x) = 
\begin{cases} 
      \frac{1}{2\lambda} &amp; \frac{||x - x_0||}{\lambda} \le 1 \\
      0 &amp; \frac{||x - x_0||}{\lambda} &gt; 1 \\
\end{cases}
\]</span></p>
</div>
</div>
<div id="simulating-time-to-event-data" class="section level2">
<h2 class="hasAnchor">
<a href="#simulating-time-to-event-data" class="anchor"></a>Simulating time-to-event data</h2>
<p>Next, let’s simulate some data that we will later to get experience using the <strong>sjosmooth</strong> package. We’ll simulate the relationship between the predictors and the outcome to be non-linear (when using the Cox regression model).</p>
<p>The Cox proportional hazards regression estimates the hazard, <span class="math inline">\(h(t)\)</span> <span class="math display">\[
h(t) = h_0(t)exp(\boldsymbol{X}\beta)
\]</span> where <span class="math inline">\(h_0(t)\)</span> is the baseline hazard and <span class="math inline">\(\boldsymbol{X}\beta\)</span> is the linear predictor. We’re going to keep these simulations simple and assume a constant baseline hazard of 1 (i.e. <span class="math inline">\(h_0(t) = 1\)</span>). As a result the cumulative baseline hazard takes the form <span class="math inline">\(H_0(t) = t\)</span>. The survival probability function is <span class="math display">\[
S(t; X) = exp(-H_0(t)*exp(\boldsymbol{X}\beta))
\]</span> which is simply <span class="math inline">\(1 - F(t; \boldsymbol{X})\)</span>. <span class="math inline">\(F(t; X)\)</span> is well known to follow a uniform distribution (<span class="math inline">\(U(0,1)\)</span>). If <span class="math inline">\(U \sim U(0,1)\)</span> it follows that <span class="math inline">\(1 - U \sim U(0,1)\)</span>. Therefore, <span class="math inline">\(S(t; X) \sim U(0,1)\)</span>. We can use these results to simulate survival data from a Cox regression model. Survival times, <span class="math inline">\(T\)</span>, can be simulated by <span class="math display">\[
T = H_0^{-1}(- \log (U)exp(-\boldsymbol{X}\beta))
\]</span> Because we’ve assumed a simple baseline hazard, <span class="math inline">\(H_0^{-1}(t) = t\)</span>. Therefore, <span class="math display">\[
T = - \log (U)exp(-\boldsymbol{X}\beta)
\]</span></p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#kernel-smoothing-theory">Kernel Smoothing Theory</a></li>
      <li><a href="#simulating-time-to-event-data">Simulating time-to-event data</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Daniel D. Sjoberg.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.2.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
